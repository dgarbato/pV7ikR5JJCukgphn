{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b12a2f5d",
   "metadata": {},
   "source": [
    "**MonReader project**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae78e0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70a8c3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = r'C:\\Users\\dgarb\\OneDrive\\Documents\\APZIVA\\Progect 4\\images\\training'\n",
    "test_dir = test_dir = r'C:\\Users\\dgarb\\OneDrive\\Documents\\APZIVA\\Progect 4\\images\\testing'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28b206a",
   "metadata": {},
   "source": [
    "Define image generators for both train and test data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bec434e",
   "metadata": {},
   "source": [
    "in a grey scale image each pixel has one number which values range from 0 to 255 for one number or one channel\n",
    "\n",
    "when in RGB (colors) we have three channels each with pixel values ranging from 0 to 255\n",
    "\n",
    "in an RGB image Each pixel  has three numbers: one for red, one for green and one for blue\n",
    "\n",
    "If an RGB image is 640 X 640 pixels resolution, it has 1,228,800 numbers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "372ab3da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1228800"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3*640*640"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe01a362",
   "metadata": {},
   "source": [
    "When you normalize each of the three numbers in each pixel will be between zero and one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cf8d2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2392 images belonging to 2 classes.\n",
      "Found 597 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255) #normalizing \n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(200, 200), # target size specifies dimension to which\n",
    "    batch_size=32,            # all images found in the \n",
    "    class_mode='binary')      # directory will be resized\n",
    "                            # height = 200 and width = 200\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(200, 200),\n",
    "    batch_size=32,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3c5d4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1 (Conv2D)           (None, 198, 198, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 99, 99, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 97, 97, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 48, 48, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 46, 46, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 23, 23, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 67712)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               8667264   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,760,641\n",
      "Trainable params: 8,760,641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Initialize the CNN\n",
    "model = Sequential()\n",
    "\n",
    "# Add convolutional layer\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(200, 200, 3)))  # Assuming input images are resized to 200x200 with 3 channels\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Add another convolutional layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Add another convolutional layer\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Flatten the output of the convolutional layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add a fully connected layer\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(1, activation='sigmoid'))  # Sigmoid activation for binary classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "585991d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 198, 198, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 99, 99, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 97, 97, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 48, 48, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 147456)            0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               18874496  \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,894,017\n",
      "Trainable params: 18,894,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initialize the CNN\n",
    "model = Sequential()\n",
    "\n",
    "# Add convolutional layer\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(200, 200, 3)))  # Assuming input images are resized to 200x200 with 3 channels\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Add another convolutional layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "\n",
    "# Flatten the output of the convolutional layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add a fully connected layer\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(1, activation='sigmoid'))  # Sigmoid activation for binary classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553ac5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7310229b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "75/75 [==============================] - 223s 3s/step - loss: 0.8050 - accuracy: 0.6547 - val_loss: 0.4100 - val_accuracy: 0.7906\n",
      "Epoch 2/10\n",
      "75/75 [==============================] - 241s 3s/step - loss: 0.2359 - accuracy: 0.9114 - val_loss: 0.1704 - val_accuracy: 0.9414\n",
      "Epoch 3/10\n",
      "75/75 [==============================] - 226s 3s/step - loss: 0.0762 - accuracy: 0.9770 - val_loss: 0.0781 - val_accuracy: 0.9749\n",
      "Epoch 4/10\n",
      "75/75 [==============================] - 224s 3s/step - loss: 0.0195 - accuracy: 0.9971 - val_loss: 0.0380 - val_accuracy: 0.9899\n",
      "Epoch 5/10\n",
      "75/75 [==============================] - 220s 3s/step - loss: 0.0176 - accuracy: 0.9958 - val_loss: 0.0550 - val_accuracy: 0.9883\n",
      "Epoch 6/10\n",
      "75/75 [==============================] - 217s 3s/step - loss: 0.0076 - accuracy: 0.9992 - val_loss: 0.0342 - val_accuracy: 0.9899\n",
      "Epoch 7/10\n",
      "75/75 [==============================] - 222s 3s/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9899\n",
      "Epoch 8/10\n",
      "75/75 [==============================] - 244s 3s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0307 - val_accuracy: 0.9933\n",
      "Epoch 9/10\n",
      "75/75 [==============================] - 230s 3s/step - loss: 5.5683e-04 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 0.9950\n",
      "Epoch 10/10\n",
      "75/75 [==============================] - 201s 3s/step - loss: 4.1295e-04 - accuracy: 1.0000 - val_loss: 0.0343 - val_accuracy: 0.9950\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator, epochs=10, validation_data=test_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc79f34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# machine learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f20881e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647e6a63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e98347",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5d09f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5528bae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1454c371",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46482069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9d8058",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03aa4f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b6d4e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2bd77b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5277143",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf3dbc0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
